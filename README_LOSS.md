# KotML Loss Functions

Полная реализация функций потерь для библиотеки нейронных сетей KotML.

## Архитектура

- **Базовый класс `Loss`** с виртуальными методами `Forward()`, `Backward()`, `GetName()`
- **5 реализованных функций потерь** для различных задач машинного обучения
- **Автоматическое дифференцирование** и вычисление градиентов
- **Строгая валидация** входных параметров с информативными ошибками

## Функции Потерь

| Класс | Назначение | Особенности |
|-------|------------|-------------|
| `MSELoss` | Регрессия | Стандартная функция потерь, чувствительна к выбросам |
| `MAELoss` | Регрессия | Устойчива к выбросам, линейная функция |
| `BCELoss` | Бинарная классификация | Для вероятностных предсказаний [0,1] |
| `CrossEntropyLoss` | Многоклассовая классификация | Для softmax выходов и one-hot меток |
| `HuberLoss` | Устойчивая регрессия | Комбинирует MSE и MAE |

## Быстрый Старт

```cpp
#include "kotml/nn/loss.hpp"

// Регрессия
nn::MSELoss mse;
auto loss = mse.Forward(predictions, targets);
auto gradients = mse.Backward(predictions, targets);

// Бинарная классификация
nn::BCELoss bce;
auto [loss, grads] = bce.ForwardBackward(predictions, targets);

// Многоклассовая классификация
nn::CrossEntropyLoss ce;
auto loss = ce.Forward(softmax_output, one_hot_targets);

// Convenience функции
auto mse_loss = nn::loss::MSE(predictions, targets);
auto bce_loss = nn::loss::BCE(predictions, targets);
```

## Файлы

- `include/kotml/nn/loss.hpp` - Заголовочный файл с реализацией
- `src/nn/loss.cpp` - Исходный файл (заглушка)
- `examples/loss_example.cpp` - Полный пример использования
- `docs/loss_functions.md` - Подробная документация

## Особенности Реализации

- **Полиморфизм**: Все функции наследуются от базового класса `Loss`
- **Эффективность**: Минимальное использование памяти и копирований
- **Безопасность**: Строгая валидация входных данных
- **Гибкость**: Поддержка как одиночных образцов, так и батчей
- **Численная стабильность**: Epsilon параметры для предотвращения log(0)

## Интеграция

Функции потерь легко интегрируются с:
- Оптимизаторами SGD/Adam
- Модулями нейронных сетей
- Циклами обучения
- Системой автоматического дифференцирования

## Тестирование

Запустите пример для демонстрации всех функций:

```bash
cd build
make loss_example
./examples/loss_example
```

Пример показывает:
- Использование всех 5 функций потерь
- Сравнение устойчивости к выбросам
- Валидацию параметров
- Батчевую обработку
- Интеграцию с градиентами 